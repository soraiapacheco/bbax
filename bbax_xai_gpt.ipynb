{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208cdc62-ab6e-4258-a1f0-f235ccee1a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146022cc-f264-433f-8142-6f79110cca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sorai\\demo\\lib\\site-packages (1.78.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sorai\\demo\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sorai\\demo\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sorai\\demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sorai\\demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sorai\\demo\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sorai\\demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sorai\\demo\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe0188e7-72ca-42b3-bcab-a961b63bfc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in c:\\users\\sorai\\demo\\lib\\site-packages (4.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f36983d-d19b-47ee-8a0e-8b5aa3152f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'typing_extensions' from 'c:\\\\users\\\\sorai\\\\demo\\\\lib\\\\site-packages\\\\typing_extensions.py'>\n"
     ]
    }
   ],
   "source": [
    "import typing_extensions\n",
    "print(typing_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc529037-c235-4548-8a3c-f2bf4414b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: openai 1.78.1\n",
      "Uninstalling openai-1.78.1:\n",
      "  Successfully uninstalled openai-1.78.1\n",
      "Found existing installation: typing_extensions 4.13.2\n",
      "Uninstalling typing_extensions-4.13.2:\n",
      "  Successfully uninstalled typing_extensions-4.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall openai typing_extensions -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f69724-1295-4f63-bd8d-706fd76e1ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting typing_extensions\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting openai\n",
      "  Using cached openai-1.78.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sorai\\demo\\lib\\site-packages (from openai) (4.62.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sorai\\demo\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.1.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sorai\\demo\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\sorai\\demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2021.5.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sorai\\demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sorai\\demo\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sorai\\demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sorai\\demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sorai\\demo\\lib\\site-packages (from tqdm>4->openai) (0.4.4)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached openai-1.78.1-py3-none-any.whl (680 kB)\n",
      "Installing collected packages: typing_extensions, openai\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   -------------------- ------------------- 1/2 [openai]\n",
      "   ---------------------------------------- 2/2 [openai]\n",
      "\n",
      "Successfully installed openai-1.78.1 typing_extensions-4.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.10.2 requires anyio<4,>=3.1.0, but you have anyio 4.9.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.22.4 which is incompatible.\n",
      "tensorflow 2.6.0 requires six~=1.15.0, but you have six 1.17.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.13.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ffc8b81-4c5b-4af0-9b87-aca559b9d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up your API key\n",
    "client = openai.OpenAI(api_key = \"YOUR API KEY\")\n",
    "\n",
    "class Blackboard:\n",
    "    def __init__(self):\n",
    "        self.facts = []\n",
    "        self.logs = []\n",
    "\n",
    "    def update(self, fact):\n",
    "        self.facts.append(fact)\n",
    "        print(f\"Updated blackboard with: {fact}\")\n",
    "\n",
    "class KnowledgeSource:\n",
    "    def __init__(self, name, rule, action):\n",
    "        self.name = name\n",
    "        self.rule = rule\n",
    "        self.action = action\n",
    "\n",
    "    def evaluate(self, blackboard):\n",
    "        if self.rule(blackboard):\n",
    "            result = self.action(blackboard)\n",
    "            explanation = generate_explanation(self.name, result)\n",
    "            blackboard.logs.append((self.name, explanation))\n",
    "\n",
    "class InferenceEngine:\n",
    "    def __init__(self, knowledge_sources):\n",
    "        self.knowledge_sources = knowledge_sources\n",
    "\n",
    "    def run(self, blackboard):\n",
    "        for ks in self.knowledge_sources:\n",
    "            ks.evaluate(blackboard)\n",
    "\n",
    "# Sample GPT explanation function\n",
    "def generate_explanation(ks_name, action_result):\n",
    "    prompt = f\"The knowledge source {ks_name} activated due to: {action_result}. Explain this decision in plain English.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd1e8e1e-cef4-4767-9abe-a23521b69838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated blackboard with: rain\n",
      "Updated blackboard with: Delay trains by 7 minutes due to rain\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\3366080987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0minference_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInferenceEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mKS_weather\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mblackboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rain\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0minference_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblackboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Explanation: {log[1]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\2340489726.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, blackboard)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblackboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknowledge_sources\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Sample GPT explanation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\2340489726.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, blackboard)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackboard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mexplanation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_explanation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mblackboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\2340489726.py\u001b[0m in \u001b[0;36mgenerate_explanation\u001b[1;34m(ks_name, action_result)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgenerate_explanation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mks_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"The knowledge source {ks_name} activated due to: {action_result}. Explain this decision in plain English.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     response = client.chat.completions.create(\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"role\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"user\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"content\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sorai\\demo\\lib\\site-packages\\openai\\_utils\\_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sorai\\demo\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    923\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m    926\u001b[0m             \u001b[1;34m\"/chat/completions\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             body=maybe_transform(\n",
      "\u001b[1;32mc:\\users\\sorai\\demo\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1237\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m         )\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def patch(\n",
      "\u001b[1;32mc:\\users\\sorai\\demo\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Re-raising status error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "blackboard = Blackboard()\n",
    "\n",
    "KS_weather = KnowledgeSource(\n",
    "    \"KS-Weather\",\n",
    "    lambda bb: \"rain\" in bb.facts,\n",
    "    lambda bb: bb.update(\"Delay trains by 7 minutes due to rain\") or \"Delay trains by 7 minutes due to rain\"\n",
    ")\n",
    "\n",
    "inference_engine = InferenceEngine([KS_weather])\n",
    "blackboard.update(\"rain\")\n",
    "inference_engine.run(blackboard)\n",
    "for log in blackboard.logs:\n",
    "    print(f\"Explanation: {log[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
